# Install SELF
The Spectral Element Library in Fortran can be built provided the following dependencies are met

* Fortran 2008 compliant compiler
* MPI, e.g. [OpenMPI](https://www.open-mpi.org/)
* [GNU Make](https://www.gnu.org/software/make/)
* Fortran compiler ( `gfortran` recommended )
* [HIP](https://rocm.docs.amd.com/en/latest/deploy/linux/quick_start.html)
* (Optional) [CUDA Toolkit](), if you are building for Nvidia GPU hardware.
* [HDF5](https://www.hdfgroup.org/solutions/hdf5/)
* [FluidNumerics/feq-parse](https://github.com/FluidNumerics/feq-parse)
* [jacobwilliams/JSON-Fortran](https://github.com/jacobwilliams/json-fortran)

!!! note
    Since HIP is officially supported only on CentOS, RHEL, Ubuntu, SLES, and Windows operating systems, SELF currently can only be built on these operating systems. For deployment on MacOS systems, consider using the containerized builds. For building on Windows, you will need the [AMD HIP SDK for Windows](https://www.amd.com/en/developer/rocm-hub/hip-sdk.html)

You can install SELF in two possible ways

1. Bare Metal Installation
2. Docker image

A bare metal installation will require that you have a CentOS/RHEL 7 or 8, SLES, Ubuntu 20.04 (focal) or 22.04 (jammy), or Windows operating system. You will also need to ensure that all of the dependencies are installed on your system before installing SELF.

A Docker image installation uses the Ubuntu 22.04 Docker image as a base and takes care of installing all of the dependencies for you. The resulting Docker image can be run using Docker or Singularity/Apptainer. 

This documentation will walk through steps to install SELF using bare metal installation and the Docker image approaches.


## Bare Metal Install

### Dependency installation

#### Ubuntu 20.04 / 22.04 with Spack
On your system, make sure that you have a 2008 standard compliant Fortran compiler and GNU Make installed. On Ubuntu,

```
sudo apt-get install build-essential gcc gfortran
```

To help install the remainder of SELF's dependencies, we recommend that you use [Spack](https://spack.io). SELF comes with a Spack environment file that can be used to create a spack environment on your system.

First, install Spack

```
git clone https://github.com/spack/spack ~/spack
source ~/spack/share/spack/setup-env.sh
```

You can instruct Spack to use packages that are included with your operating system. This can help speed up the installation process, and we recommend that you leverage packages already installed on your system. You can do this by running the following command : 

```
spack external find --not-buildable
```

SELF comes with a [spack environment](https://spack.readthedocs.io/en/latest/environments.html) file (`SELF/env/spack.yaml`) that defines the packages to install (`hdf5`, `json-fortran`, and `feq-parse`). You can use this environment file to easily install and make available these packages. To get started, clone the SELF repository

```
git clone https://github.com/fluidnumerics/SELF ~/SELF
```

Edit the `~/SELF/env/spack.yaml` file to set the following parameters

* `install_tree` (Default `/opt/software/self` ) - This is the path where the dependencies are installed within their own directory space
* `view` (Default `/opt/view/self`) - This is the path where all package `bin/`, `lib/`, `lib64/`, `include/`, `etc/`, and `share/` directories are symlinked.

When setting both of these locations, ensure that you have read, write, and executable access to the `install_tree` and `view` paths.

Once you've configured the environment, activate the environment

```
spack env activate -d ~/SELF/env
```

Once the environment is activated, you can use `spack find` show which packages will be installed and verify the output appears like what is shown below

```
$ spack find
==> In environment /home/joe/apps/SELF/env
==> Root specs
feq-parse@1.1.0  hdf5@1.12.2 +cxx+fortran+mpi  json-fortran@8.3.0

==> 0 installed packages
```

Next, you can install the dependencies

```
spack install
```

Installing the dependencies can take up to 30 minutes.


### Install SELF

SELF comes with a Make system that defines the build and installation process. When you install SELF, you will install the following artifacts

* `${SELF_PREFIX}/bin/self` - The main program for SELF that can be used to run unit tests, integration tests, and various conservation law solvers supported by the SELF developers, including Compressible Navier Stokes (2D), Viscous Burger's Equation (1D), and Shallow Water Equations (2D).
* `${SELF_PREFIX}/lib/libself.a` - A library for the SELF API, in case you want to build your own programs and solvers using Spectral Element Methods.
* `${SELF_PREFIX}/include/*.mod` - Module files generated by the Fortran compiler during the build process. When building your own programs that depend on SELF, you will need to add `-I${SELF_PREFIX}/include` to your compiler flags.

This part of the documentation will provide you with an overview of the environment variables that control the build process, show you how to target different GPUs for GPU acceleration, and how to install SELF to a preferred directory on your system.

#### Build Variables
There are a number of environment variables you can use to control the behavior of the build and installation process. Importantly, some of these environment variables are necessary to tell the build system where dependencies can be found.


* `MPIFC`                  Set the full path to a MPI fortran compiler. (Default: mpifort)
* `HIPCC`                  Set the full path to a HIP compiler. (Default: /opt/rocm/bin/hipcc)
* `SELF_FFLAGS`            Set the flags to send to the fortran compiler. (Default: -cpp -pg -g -O0 -C -Wall -fbounds-check -fbacktrace --coverage -ffpe-trap=invalid,zero,overflow)
* `GPU_TARGET`             Set the target GPU microarchitecutre. (Default: gfx906 | Options gfx900, gfx906, gfx90a, sm35, sm50, sm70) 
* `HIP_PLATFORM`           Set the target vendor platform. (Default: amd | Options amd, nvidia) 
* `SELF_PREFIX`            Set the path to install SELF (Default: /opt/self)
* `SELF_DIR`               Set the path to the repository root ( Default $(shell pwd) )
* `PREC`                   Set the floating point precision in SELF. (Default: single | Options : single, double)
* `ROCM_DIR`               Set the path to ROCm installation (Default: /opt/rocm)
* `CUDA_PATH`              Set the path to CUDA installation (Default: /usr/local/cuda) (Needed if GPU_TARGET is an Nvidia GPU)
* `SELF_GPU_LIBS`          Set the linker flags for either HIP(Default) or CUDA (Default: -L/opt/rocm/lib -lamdhip64)
* `SELF_GPU_INC`           Set the includes flags for either HIP(Default) or CUDA (Default: -I/opt/rocm/include)
* `SELF_JSONF_LIBS`        Set the linker flags for json-fortran (Default: -L/opt/view/self/lib -ljsonfortran)
* `SELF_JSONF_INC`         Set the includes flags for json-fortran (Default: -I/opt/view/self/include)
* `SELF_FEQPARSE_LIBS`     Set the linker flags for feq-parse (Default: -L/opt/view/self/lib -lfeqparse)
* `SELF_FEQPARSE_INC`      Set the includes flags for feq-parse (Default: -I/opt/view/self/include)
* `SELF_HDF5_LIBS`         Set the linker flags for hdf5 (Default: -L/opt/view/self/lib -lhdf5_fortran -lhdf5 -lz -lm)
* `SELF_HDF5_INC`          Set the includes flags for hdf5 (Default: -I/opt/view/self/include/shared)


The default values of these variables will work for you if the following conditions are met
* You've used the spack environment installation for the dependencies, with the `view` set to `/opt/view/self`.
* The spack environment is active
* ROCm is installed in a default location
* The target GPU you are building for is the AMD MI50

#### Building for an Nvidia GPU 
To build SELF for running on Nvidia GPUs, you will need to have both HIP and the CUDA toolkit installed on your system. Set the `HIP_PLATFORM` to `nvidia`

```
export HIP_PLATFORM=nvidia
```

Next, you will need to set the `GPU_TARGET` to the microarchicture code for the specific GPU you are targeting (see the table below). 

Pascal (P100) | Volta (V100) | Ampere (A100) | Hopper (H100) |
------------- | ------------ | ------------- | ------------- |
sm_60, sm_61, sm_62 | sm_70, sm_72 | sm_80, sm_86, sm_87 | sm_90, sm_90a |

For example, to build for the H100 GPUs, 

```
export GPU_TARGET=sm_90
```

If the CUDA toolkit is installed in a location other than `/usr/local/cuda` you will need to set `CUDA_PATH` to the path of your local CUDA installation.

#### Install SELF
Before building SELF, set the `INSTALL_PREFIX` environment variable to a path on your system where you would like to install SELF and where you have read,write, and executable permissions.

```
export SELF_PREFIX=${HOME}/apps/self
```

The example above will cause SELF artifacts to be installed in `${HOME}/apps/self`.

To build and install SELF, you can easily run 
```
make install
```

[If you encounter any problems, feel free to open an new issue](https://github.com/FluidNumerics/SELF/issues/new/choose)

## Build a Docker Container
SELF comes with Docker files defined under the `docker/` subdirectory. Currently, there are recipes for building container images for AMD GPUs (`Dockerfile.rocm`) and Nvidia GPUs (`Dockerfile.cuda`). The recipes will install all of SELF's dependencies and SELF in a container image based on the Ubuntu 22.04 image. To bake a SELF image, first clone the SELF repository and navigate to the source code directory

```
git clone https://github.com/fluidnumerics/SELF ${HOME}/SELF
cd ${HOME}/SELF
```

In this example, SELF is cloned to `${HOME}/SELF`. From the main directory of the SELF repository, you can use `docker build` to build a container image.

```
docker build -f docker/Dockerfile.rocm -t self:test .
```

This command will create a Docker image for running SELF on AMD MI50 GPUs and the image is tagged `self:test`; this is the name of the image that you will reference when running SELF.

        
By default, this will build SELF with double precision floating point arithmetic, no optimizations (debug build), and with GPU kernels offloaded to a AMD MI50 GPUs. You can customize the behavior of the build process by using build substitutions. The following build substitution variables are currently available

* `_PREC` : The floating point precision to use in SELF; either `single` or `double`
* `_GPU_TARGET`: GPU microarchitecture code to build for. Defaults to `gfx906` (AMD MI50)
* `_HIP_PLATFORM`: The value to set for the `HIP_PLATFORM` environment variable. Either `nvidia` or `amd`
* `_FFLAGS` : The compiler flags to send to the fortran compiler.