# Install SELF


## Quick start
The easiest way to get started is to use the spack package manager. On a Linux platform, set up spack

```
git clone https://github.com/spack/spack ~/spack
source ~/spack/share/spack/setup-env.sh
```

Allow spack to locate your compilers (make sure you have C, C++, and Fortran compilers installed!)

```
spack compiler find
```

To reduce build time, import existing packages on your system
```
spack external find
```

Then, clone SELF
```
git clone https://github.com/fluidnumerics/SELF ~/SELF
cd ~/SELF
```

Install SELF's dependencies (OpenMPI, HDF5, and feq-parse)
```
sudo -i spack -e . install --no-check-signature
```

Then, install SELF
```
cd ~/SELF
spack env activate .
mkdir ~/SELF/build
cd ~/SELF/build
cmake -DCMAKE_INSTALL_PREFIX=/opt/view ../
make
make test
sudo make install
```



## Dependencies
The Spectral Element Library in Fortran can be built provided the following dependencies are met

* [Cmake (v3.21 or greater)](https://cmake.org/resources/)
* Fortran 2008 compliant compiler ( `gfortran` recommended )
* MPI, e.g. [OpenMPI](https://www.open-mpi.org/)
* [MAGMA](https://icl.utk.edu/magma/)
* [HDF5](https://www.hdfgroup.org/solutions/hdf5/)
* [FluidNumerics/feq-parse](https://github.com/FluidNumerics/feq-parse)
* (Optional, AMD GPU Support) [ROCm v5.7.0 or greater](https://rocm.docs.amd.com/projects/install-on-linux/en/latest/)
* (Optional, Nvidia GPU Support) [CUDA Toolkit](https://developer.nvidia.com/cuda-toolkit)


## Installation Notes

### GPU Support 
SELF uses OpenMP for GPU offloading. Some of our "heavy-lifting" kernels, such as divergence, gradient, and grid interpolation operations are expressed using the BLAS API. For these, we use MAGMA.


## Bare Metal Install

### Install SELF with CMake

!!! warning
    It is assumed that you have all of the necessary dependencies installed on your system before proceeding any further.

SELF comes with a CMake build system that defines the build and installation process. When you install SELF, you will install the following artifacts

* `${CMAKE_INSTALL_PREFIX}/lib/libself-static.a` - A static library for the SELF API, in case you want to build your own programs and solvers using Spectral Element Methods.
* `${CMAKE_INSTALL_PREFIX}/lib/libself.so` - A static library for the SELF API, in case you want to build your own programs and solvers using Spectral Element Methods.
* `${CMAKE_INSTALL_PREFIX}/include/*.mod` - Module files generated by the Fortran compiler during the build process.
* `${CMAKE_INSTALL_PREFIX}/example/*` - A set of example programs that run simple linear models (advection-diffusion) in 1-D, 2-D, or 3-D
* `${CMAKE_INSTALL_PREFIX}/test/*` - A set of unit tests that exercise specific methods beneath the `model` classes.

This part of the documentation will provide you with an overview of the environment variables that control the build process, show you how to target different GPUs for GPU acceleration, and how to install SELF to a preferred directory on your system.

#### Build Variables
There are a number of environment variables you can use to control the behavior of the build and installation process. Importantly, some of these environment variables are necessary to tell the build system where dependencies can be found.

* `CMAKE_INSTALL_PREFIX`      The installation path for SELF
* `CMAKE_BUILD_TYPE`          Type of build, one of `Release`, `Debug`, or `Coverage`

The default values of these variables will work for you if the following conditions are met
* You have all of the necessary dependencies installed and visible in your `PATH` and `LD_LIBRARY_PATH` environment variables
* ROCm is installed in `/opt/rocm` (the default location)
* If you are targeting Nvidia GPUs, CUDA is installed in `/usr/local/cuda` (the default location)

#### Building for an Nvidia GPU 
To build SELF for running on Nvidia GPUs, you will need to have both HIP and the CUDA toolkit installed on your system.

Next, you will need to set the `CMAKE_HIP_ARCHITECTURES` build variable to the microarchicture code for the specific GPU you are targeting (see the table below). 

Pascal (P100) | Volta (V100) | Ampere (A100) | Hopper (H100) |
------------- | ------------ | ------------- | ------------- |
sm_60, sm_61, sm_62 | sm_70, sm_72 | sm_80, sm_86, sm_87 | sm_90, sm_90a |


#### Install SELF (Detailed)
First, clone the SELF repository (if you haven't already)
```
git clone https://github.com/fluidnumerics/SELF ~/SELF
```

Next, create a build directory for Cmake to stage intermediate files
```
mkdir ~/SELF/build
cd ~/SELF/build
```

Use Cmake to build the make system
```
 FC=gfortran \
    cmake -DCMAKE_PREFIX_PATH=/opt/rocm
          -DCMAKE_HIP_ARCHITECTURES=gfx90a \
          -DCMAKE_INSTALL_PREFIX=${HOME}/opt/self \
          -DCMAKE_BUILD_TYPE=Release \
          ./ 
```
In this example, 
* `FC=gfortran` sets the fortran compiler to `gfortran`.
* `CMAKE_PREFIX_PATH` instructs Cmake to search for Cmake configuration files for ROCm underneath `/opt/rocm`
* `CMAKE_HIP_ARCHITECTURES=gfx90a` sets the target GPU architecture to the AMD MI200 series GPUs
* `CMAKE_INSTALL_PREFIX=${HOME}/opt/self` sets the installation path for SELF to `${HOME}/opt/self`; when setting this variable, make sure it is a location where you have read and write permissions
* `CMAKE_BUILD_TYPE=Release` sets the build type to `Release`, which enables `-O3` optimizations. If you are troubleshooting an issue, it is best to set this to `Debug`.

After running `cmake`, you can build SELF,
```
make VERBOSE=1
```

We recommend that you run the unit tests included with SELF,
```
ctest --test-dir ~/SELF/build/
```

If all of the tests pass, install SELF
```
make install
```

At the end of this process, the `self` application is installed under `${HOME}/opt/self/bin`. Additionally, the SELF static library can be found under `${HOME}/opt/self/lib` and the `.mod` files for all of the SELF modules are under `${HOME}/opt/self/include`.

[If you encounter any problems, feel free to open an new issue](https://github.com/FluidNumerics/SELF/issues/new/choose)